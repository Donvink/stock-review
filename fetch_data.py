import akshare as ak
import pandas as pd
from datetime import datetime, timedelta
import os
import time
import pytz


def load_local_csv(file_path=""):
    """ä»æœ¬åœ° CSV æ–‡ä»¶åŠ è½½æ•°æ®"""
    if os.path.exists(file_path):
        # print(f"ğŸ“‚ å‘ç°æœ¬åœ°ç¼“å­˜ï¼Œæ­£åœ¨è¯»å–: {file_path}")
        df = pd.read_csv(file_path, dtype={'ä»£ç ': str}) # å¼ºåˆ¶ä»£ç åˆ—ä¸ºå­—ç¬¦ä¸²ï¼Œé˜²æ­¢ 000001 å˜æˆ 1
        return df
    else:
        # print(f"âš ï¸ æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return None

def stock_summary(date="20260213", save_dir='data'):
    """è·å–å¤§ç›˜æ•°æ®"""
    file_path = f"{save_dir}/index_{date}.csv"

    # 1. å„å¤§æŒ‡æ•°æ‘˜è¦æ•°æ®
    index_df = load_local_csv(file_path)
    if index_df is not None:
        # total_amount = index_df.loc[len(index_df) - 1, 'æˆäº¤é¢']
        return index_df
    else:
        try:
            # index_df = ak.stock_zh_index_spot_em()
            index_df = ak.stock_zh_index_spot_sina()
            # print(index_df)
        except Exception as e:
            print(f"âš ï¸ è·å–æŒ‡æ•°æ•°æ®å¤±è´¥: {e}")
            return None

    target_indices = ["sh000001", "sz399001"]

    # 2. ç­›é€‰å‡ºä¸¤åªæŒ‡æ•°
    result = index_df[index_df['ä»£ç '].isin(target_indices)].copy()

    # 3. æ•°æ®æ¸…ç†ï¼šå°†å­—ç¬¦ä¸²è½¬ä¸ºæ•°å€¼
    result['æˆäº¤é¢'] = pd.to_numeric(result['æˆäº¤é¢'])
    result['æ¶¨è·Œå¹…'] = pd.to_numeric(result['æ¶¨è·Œå¹…'])

    # 4. è®¡ç®—æ±‡æ€»æˆäº¤é¢
    total_amount = result['æˆäº¤é¢'].sum()

    # 5. æ„é€ â€œæ±‡æ€»â€è¡Œæ•°æ®
    summary_row = {
        'ä»£ç ': 'Total',
        'åç§°': 'æ²ªæ·±æ€»æˆäº¤é¢',
        'æœ€æ–°ä»·': None,  # æ±‡æ€»è¡Œä¸éœ€è¦æœ€æ–°ä»·
        'æˆäº¤é¢': total_amount,
        'æ¶¨è·Œå¹…': None  # ä¸¤ä¸ªæŒ‡æ•°çš„æ¶¨å¹…ä¸èƒ½ç›´æ¥ç›¸åŠ ï¼Œæ‰€ä»¥å¡« None æˆ–ä¿æŒä¸ºç©º
    }

    # 6. å°†æ±‡æ€»è¡Œè¿½åŠ åˆ° DataFrame ä¸­
    # ä½¿ç”¨ pd.DataFrame è½¬æ¢ä¸€ä¸‹å†è¿æ¥
    result = pd.concat([result, pd.DataFrame([summary_row])], ignore_index=True)

    # 7. æ ¼å¼åŒ–è¾“å‡ºï¼šå°†æˆäº¤é¢è½¬ä¸ºâ€œäº¿å…ƒâ€æ›´ç›´è§‚
    result['æˆäº¤é¢(äº¿å…ƒ)'] = (result['æˆäº¤é¢'] / 1e8).round(2)
    result.insert(0, 'åºå·', range(1, len(result) + 1))
    result.to_csv(file_path, index=False, encoding="utf-8-sig")
    
    print("-" * 30)
    print(result[['åºå·', 'ä»£ç ', 'åç§°', 'æœ€æ–°ä»·', 'æ¶¨è·Œå¹…', 'æˆäº¤é¢(äº¿å…ƒ)']])
    print("-" * 30)
    return result

def stock_zt_dt_pool(date="20260213", save_dir='data'):
    """è·å–æ¶¨åœ/è·Œåœä¸ªè‚¡æ•°æ®"""
    zt_file_path = f"{save_dir}/zt_pool_{date}.csv"
    dt_file_path = f"{save_dir}/dt_pool_{date}.csv"
    zb_file_path = f"{save_dir}/zb_pool_{date}.csv"

    # 1. å„å¤§æŒ‡æ•°æ‘˜è¦æ•°æ®
    zt_pool_df = load_local_csv(zt_file_path)
    dt_pool_df = load_local_csv(dt_file_path)
    zb_pool_df = load_local_csv(zb_file_path)
    if zt_pool_df is None or dt_pool_df is None or zb_pool_df is None:
        try:
            zt_pool_df = ak.stock_zt_pool_em(date=date)
            time.sleep(0.5) # é¿å…è¯·æ±‚è¿‡å¿«è¢«å°
            dt_pool_df = ak.stock_zt_pool_dtgc_em(date=date)
            time.sleep(0.5) # é¿å…è¯·æ±‚è¿‡å¿«è¢«å°
            zb_pool_df = ak.stock_zt_pool_zbgc_em(date=date)
            time.sleep(0.5) # é¿å…è¯·æ±‚è¿‡å¿«è¢«å°
            
            zt_pool_df.to_csv(zt_file_path, index=False, encoding="utf-8-sig")
            # print(f"âœ… æˆåŠŸè·å–æ¶¨åœæ¿æ•°æ®ï¼Œä¿å­˜è‡³: {zt_file_path}")
            dt_pool_df.to_csv(dt_file_path, index=False, encoding="utf-8-sig")
            # print(f"âœ… æˆåŠŸè·å–è·Œåœæ¿æ•°æ®ï¼Œä¿å­˜è‡³: {dt_file_path}")
            zb_pool_df.to_csv(zb_file_path, index=False, encoding="utf-8-sig")
            # print(f"âœ… æˆåŠŸè·å–ç‚¸æ¿æ•°æ®ï¼Œä¿å­˜è‡³: {zb_file_path}")
        except Exception as e:
            print(f"âš ï¸ è·å–æ¶¨åœæ¿æ•°æ®å¤±è´¥: {e}")
            return None, None, None
            
    zt_stocks = len(zt_pool_df)
    dt_stocks = len(dt_pool_df)
    zb_stocks = len(zb_pool_df)

    print("-" * 30)
    print(f"ğŸ“Š {date} æ¶¨åœè‚¡æ•°é‡: {zt_stocks}ï¼Œè·Œåœè‚¡æ•°é‡: {dt_stocks}ï¼Œç‚¸æ¿è‚¡æ•°é‡: {zb_stocks}")
    print("-" * 30)
    
    return zt_pool_df, dt_pool_df, zb_pool_df

def fetch_all_stock_data(date='20260213', save_dir='data', max_retries=3):
    """å°è¯•æŠ“å–æ‰€æœ‰è‚¡ç¥¨æ•°æ®ï¼Œå¤±è´¥åˆ™é‡è¯•"""
    file_path = f"{save_dir}/A_stock_{date}.csv"

    df = load_local_csv(file_path)
    if df is None:
        sucess = False
        for i in range(max_retries):
            try:
                print(f"å°è¯•ç¬¬ {i+1} æ¬¡æŠ“å–...")
                # æ ¸å¿ƒæ¥å£
                if i % 2 == 0:
                    # é¦–é€‰ï¼šä¸œæ–¹è´¢å¯Œå®æ—¶æ¥å£ï¼ˆæ•°æ®æœ€å…¨ï¼Œå«ä»£ç ã€åç§°ã€æ¶¨è·Œå¹…ã€æˆäº¤é¢ç­‰ï¼‰
                    df = ak.stock_zh_a_spot_em()
                elif i % 2 == 1:
                    # å¤‡é€‰ 1ï¼šæ–°æµªæ¥å£ï¼ˆåœ¨äº‘æœåŠ¡å™¨ä¸Šæå…¶ç¨³å®šï¼Œè™½æ•°æ®å­—æ®µç•¥å°‘ï¼Œä½†åŸºæœ¬è¡Œæƒ…éƒ½æœ‰ï¼‰
                    print("âš ï¸ å°è¯•ä½¿ç”¨æ–°æµªç¨³å¥æ¥å£...")
                    df = ak.stock_zh_a_spot()
                
                if df is not None and not df.empty:
                    df.to_csv(file_path, index=False, encoding="utf-8-sig")
                    print("âœ… æ•°æ®æŠ“å–æˆåŠŸï¼")
                    print(f"ğŸ’¾ æ•°æ®å·²å­˜è‡³: {file_path}")
                    sucess = True
                    break
            except Exception as e:
                print(f"âš ï¸ ç¬¬ {i+1} æ¬¡æŠ“å–å¼‚å¸¸: {e}")
                time.sleep(5) # ç­‰ 5 ç§’å†è¯•
        if not sucess:
            print("âŒ æ‰€æœ‰é‡è¯•å‡å¤±è´¥ã€‚")
            # exit(1)
            return None, None, None, None
    
    # è®¡ç®—æ¶¨è·Œä¸ªæ•°
    df['æ¶¨è·Œ'] = df['æ¶¨è·Œå¹…'].apply(lambda x: 1 if x > 0 else (-1 if x < 0 else 0))
    up_count = df[df['æ¶¨è·Œ'] == 1].shape[0]
    down_count = df[df['æ¶¨è·Œ'] == -1].shape[0]
    flat_count = df[df['æ¶¨è·Œ'] == 0].shape[0]

    print("-" * 30)
    print(f"ğŸ“ˆ ä¸Šæ¶¨è‚¡æ•°: {up_count}, ğŸ“‰ ä¸‹è·Œè‚¡æ•°: {down_count}, ğŸ“Š æŒå¹³è‚¡æ•°: {flat_count}")
    print("-" * 30)

    return df, up_count, down_count, flat_count

def get_latest_date(max_try=20):
    """è·å–æœ€æ–°å¯ç”¨æ•°æ®çš„æ—¥æœŸ"""
    today = datetime.now().strftime("%Y%m%d")
    try:
        zt_pool_df = ak.stock_lhb_detail_daily_sina(date=today)
        return today
    except Exception:
        i = 1
        while i <= max_try:
            check_date = (datetime.now() - timedelta(days=i)).strftime("%Y%m%d")
            try:
                time.sleep(0.5) # é¿å…è¯·æ±‚è¿‡å¿«è¢«å°
                zt_pool_df = ak.stock_lhb_detail_daily_sina(date=check_date)
                break
            except Exception:
                i += 1
        if i <= max_try:
            print(f"âœ… æœ€æ–°å¯ç”¨æ•°æ®æ—¥æœŸ: {check_date} (é€šè¿‡å›æº¯ {i} å¤©æ‰¾åˆ°)")
            return check_date
        print(f"âš ï¸ å›æº¯{max_try}å¤©åä»æœªæ‰¾åˆ°å¯ç”¨æ•°æ®ï¼Œæ— æ³•ç¡®å®šæœ€æ–°æ—¥æœŸã€‚")
        return None

def get_stocks_info(df):
    """è·å–ä¸ªè‚¡æ‰€å±æ¿å—/æ¦‚å¿µä¿¡æ¯"""
    industry_frequency = {} # ç»Ÿè®¡è¡Œä¸šå‡ºç°é¢‘æ¬¡çš„å­—å…¸
    # ç¡®ä¿ DataFrame åŒ…å«å¿…è¦çš„åˆ—ï¼Œå¦‚æœç¼ºå¤±åˆ™æ·»åŠ ç©ºåˆ—
    for col in ['æ¿å—ä»£ç ', 'æ¿å—åç§°', 'ä¸»è¥ä¸šåŠ¡', 'æ¿å—æ¬¡æ•°']:
        if col not in df.columns:
            df[col] = None
    for index, row in df.iterrows():
        code = row['ä»£ç ']
        code = code[-6:] if len(code) > 6 else code # ç¡®ä¿ä»£ç æ˜¯6ä½
        # åˆ¤æ–­æ˜¯å¦æ˜¯ç§‘åˆ›æ¿ï¼ˆ688å¼€å¤´ï¼‰æˆ–åˆ›ä¸šæ¿ï¼ˆ300å¼€å¤´ï¼‰ï¼Œå¦‚æœæ˜¯åˆ™åŠ ä¸Šå‰ç¼€
        if code.startswith('688'):
            code = 'SH' + code
        elif code.startswith('300'):
            code = 'SZ' + code
        else:
            code = 'SH' + code if code.startswith('6') else 'SZ' + code
        try:
            # info_df = ak.stock_individual_info_em(symbol=code)    # ä¸œæ–¹è´¢å¯Œ
            info_df = ak.stock_individual_basic_info_xq(symbol=code) # é›ªçƒ
            # print(info_df)
            info_dict = info_df.set_index('item')['value'].to_dict()
            ind_code = info_dict.get('affiliate_industry').get('ind_code')
            ind_name = info_dict.get('affiliate_industry').get('ind_name')
            df.at[index, 'æ¿å—ä»£ç '] = ind_code
            df.at[index, 'æ¿å—åç§°'] = ind_name
            df.at[index, 'ä¸»è¥ä¸šåŠ¡'] = info_dict.get('main_operation_business')
            
            # ç»Ÿè®¡è¡Œä¸šå‡ºç°é¢‘æ¬¡çš„å­—å…¸ï¼Œä¼˜å…ˆè·å–å‡ºç°é¢‘æ¬¡è¾ƒé«˜çš„æ¿å—ä¿¡æ¯
            if ind_code is not None:
                industry_frequency[ind_code] = industry_frequency.get(ind_code, 0) + 1
                df.at[index, 'æ¿å—æ¬¡æ•°'] = industry_frequency[ind_code]
            time.sleep(0.5) # é¿å…è¯·æ±‚è¿‡å¿«è¢«å°
        except Exception as e:
            print(f"âš ï¸ è·å– {code} æ¿å—ä¿¡æ¯å¤±è´¥: {e}")
    return True

def get_top_amount_stocks(df, top_n=20, date="20260213", save_dir='data'):
    """è·å–æˆäº¤é¢å‰ N çš„ä¸ªè‚¡ä¿¡æ¯"""
    file_path = f"{save_dir}/top_amount_stocks_{date}.csv"
    top_stocks_df = load_local_csv(file_path)
    if top_stocks_df is not None:
        print("-" * 30)
        print(top_stocks_df)
        print('-' * 30)
        return top_stocks_df
    else:
        try:
            top_stocks_df = df.sort_values(by='æˆäº¤é¢', ascending=False).head(top_n).copy()

            top_stocks_df.reset_index(drop=True, inplace=True)
            top_stocks_df['æˆäº¤é¢(äº¿å…ƒ)'] = (top_stocks_df['æˆäº¤é¢'] / 1e8).round(2)
            # top_stocks_df['ç«ä»·æ¶¨å¹…(%)'] = ((top_stocks_df['ä»Šå¼€'] - top_stocks_df['æ˜¨æ”¶']) / top_stocks_df['æ˜¨æ”¶'] * 100).round(2)
            # top_stocks_df['å®ä½“æ¶¨å¹…(%)'] = ((top_stocks_df['æœ€æ–°ä»·'] - top_stocks_df['ä»Šå¼€']) / top_stocks_df['ä»Šå¼€'] * 100).round(2)

            top_stocks_df = top_stocks_df[['ä»£ç ', 'åç§°', 'æœ€æ–°ä»·', 'æ¶¨è·Œå¹…', 'æˆäº¤é¢(äº¿å…ƒ)']]

            get_stocks_info(top_stocks_df)
        except Exception as e:
            print(f"âš ï¸ è·å–æˆäº¤é¢å‰ N çš„ä¸ªè‚¡ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    top_stocks_df.insert(0, 'åºå·', range(1, len(top_stocks_df) + 1))

    print("-" * 30)
    print(f"ğŸ“ˆ æˆäº¤é‡å‰ {top_n} ä¸ªè‚¡ä¿¡æ¯:")
    print(top_stocks_df)
    print('-' * 30)

    # ä¿å­˜åˆ°æ–‡ä»¶
    top_stocks_df.to_csv(file_path, index=False, encoding="utf-8-sig")

    return top_stocks_df

def get_industry_summary(date="20260213", save_dir='data'):
    """è·å–è¡Œä¸šæ¿å—ä¿¡æ¯"""
    file_path = f"{save_dir}/industry_summary_{date}.csv"

    # 1. å„å¤§æŒ‡æ•°æ‘˜è¦æ•°æ®
    industry_summary_df = load_local_csv(file_path)
    if industry_summary_df is None:
        try:
            industry_summary_df = ak.stock_board_industry_summary_ths()
            # print(industry_summary_df)
        except Exception as e:
            print(f"âš ï¸ è·å–è¡Œä¸šæ¿å—æ•°æ®å¤±è´¥: {e}")
            return None

    # å–top 5 è¡Œä¸šæ¿å—æ•°æ®
    industry_summary_df = industry_summary_df.head(5).copy()

    industry_summary_df.to_csv(file_path, index=False, encoding="utf-8-sig")
    
    print("-" * 30)
    # print(industry_summary_df[['ä»£ç ', 'åç§°', 'æœ€æ–°ä»·', 'æ¶¨è·Œå¹…', 'æˆäº¤é¢(äº¿å…ƒ)']])
    # industry_summary_df = industry_summary_df[['æ¿å—åç§°', 'æ¿å—ä»£ç ', 'æ¶¨è·Œå¹…', 'ä¸Šæ¶¨å®¶æ•°', 'ä¸‹è·Œå®¶æ•°', 'é¢†æ¶¨è‚¡ç¥¨', 'é¢†æ¶¨è‚¡ç¥¨-æ¶¨è·Œå¹…']]
    print(industry_summary_df)
    print("-" * 30)
    return industry_summary_df

def get_concept_summary(date="20260213", save_dir='data', top_n=5):
    """è·å–æ¦‚å¿µæ¿å—ä¿¡æ¯"""
    file_path = f"{save_dir}/concept_summary_{date}.csv"

    concept_summary_df = load_local_csv(file_path)
    if concept_summary_df is None:
        try:
            concept_summary_df = ak.stock_board_concept_name_em()
            # print(concept_summary_df)
        except Exception as e:
            print(f"âš ï¸ è·å–æ¦‚å¿µæ¿å—æ•°æ®å¤±è´¥: {e}")
            return None

    # å–top_n æ¿å—æ•°æ®
    concept_summary_df = concept_summary_df.head(top_n).copy()

    concept_summary_df.to_csv(file_path, index=False, encoding="utf-8-sig")
    
    print("-" * 30)
    # print(industry_summary_df[['ä»£ç ', 'åç§°', 'æœ€æ–°ä»·', 'æ¶¨è·Œå¹…', 'æˆäº¤é¢(äº¿å…ƒ)']])
    print(concept_summary_df)
    print("-" * 30)
    return concept_summary_df

def get_concept_cons(df, date="20260213", save_dir='data', top_n=15):
    """è·å–æ¦‚å¿µæ¿å—æˆåˆ†è‚¡ä¿¡æ¯"""
    all_concept_cons = [] # ç”¨äºå­˜å‚¨æ‰€æœ‰æ¦‚å¿µæ¿å—æˆåˆ†è‚¡æ•°æ®
    all_concept_cons_topn = [] # ç”¨äºå­˜å‚¨æ‰€æœ‰æ¦‚å¿µæ¿å—æˆåˆ†è‚¡æ•°æ®

    num_concepts = df.shape[0]
    for i in range(num_concepts):
        file_path = f"{save_dir}/concept_cons_{i}_{date}.csv"
        concept_cons_df = load_local_csv(file_path)
        if concept_cons_df is not None:
            all_concept_cons.append(concept_cons_df)
            concept_cons_df.sort_values(by='æ¶¨è·Œå¹…', ascending=False, inplace=True)
            concept_cons_df = concept_cons_df.head(top_n).copy()
            all_concept_cons_topn.append(concept_cons_df)

    if len(all_concept_cons) < num_concepts:
        all_concept_cons = []
        try:
            for index, row in df.iterrows():
                concept_cons_df = ak.stock_board_concept_cons_em(symbol=row['æ¿å—åç§°'])
                # å–å‰top_nä¸ªæˆåˆ†è‚¡æ•°æ®
                concept_cons_df.sort_values(by='æ¶¨è·Œå¹…', ascending=False, inplace=True)
                concept_cons_df['æ‰€å±æ¿å—'] = row['æ¿å—åç§°']
                all_concept_cons.append(concept_cons_df)
                concept_cons_df = concept_cons_df.head(top_n).copy()
                all_concept_cons_topn.append(concept_cons_df)
                # print(concept_cons_df)
                file_path = f"{save_dir}/concept_cons_{index}_{date}.csv"
                concept_cons_df.to_csv(file_path, index=False, encoding="utf-8-sig")
                time.sleep(0.5) # é¿å…è¯·æ±‚è¿‡å¿«è¢«å°
        except Exception as e:
            print(f"âš ï¸ è·å–æ¦‚å¿µæ¿å—æˆåˆ†è‚¡æ•°æ®å¤±è´¥: {e}")
            return None
    
    print("-" * 30)
    all_concept_cons_df = pd.concat(all_concept_cons_topn, ignore_index=True)
    print(all_concept_cons_df)
    print("-" * 30)
    return all_concept_cons, all_concept_cons_topn

def get_lhb_data(date="20260213", save_dir='data'):
    """è·å–é¾™è™æ¦œæ•°æ®"""
    file_path = f"{save_dir}/lhb_{date}.csv"

    lhb_df = load_local_csv(file_path)
    if lhb_df is None:
        try:
            # lhb_df_ori = ak.stock_lhb_detail_em(start_date=date, end_date=date)
            lhb_df_ori = ak.stock_lhb_detail_daily_sina(date=date)
            
            # å»æ‰åç§°å¸¦æœ‰â€œSTâ€çš„è‚¡ç¥¨
            col_name = 'åç§°' if 'åç§°' in lhb_df_ori.columns else 'è‚¡ç¥¨åç§°'
            lhb_df = lhb_df_ori[~lhb_df_ori[col_name].str.contains('ST', case=False, na=False)].copy()
            # è‚¡ç¥¨å»é‡
            lhb_df.drop_duplicates(subset=[col_name], inplace=True)
            lhb_df.drop(columns=['åºå·'], inplace=True, errors='ignore')
            lhb_df.reset_index(drop=True, inplace=True)
            lhb_df.insert(0, 'åºå·', range(1, len(lhb_df) + 1))
            # print(lhb_df_ori)
            lhb_df.to_csv(file_path, index=False, encoding="utf-8-sig")
        except Exception as e:
            print(f"âš ï¸ è·å–é¾™è™æ¦œæ•°æ®å¤±è´¥: {e}")
            return None
    
    print("-" * 30)
    print(lhb_df)
    print("-" * 30)
    return lhb_df

def get_watchlist(top_amount_stocks_df,
                    zt_pool_df,
                    zb_pool_df,
                    dt_pool_df,
                    lhb_df,
                    concept_cons,
                    date="20260213",
                    save_dir='data'
                ):
    """
    è·å–ç²¾ç¡®å±æ€§çš„é‡ç‚¹ä¸ªè‚¡ä¿¡æ¯
    watchlist1 (å¤§é¢å¼‚åŠ¨æ± ): æˆäº¤é¢å‰äºŒåï¼Œä¸”åœ¨æ¶¨/è·Œ/ç‚¸åœæ¿ä¸Šã€æˆ–è€…åœ¨é¾™è™æ¦œä¸Šã€æˆ–è€…åœ¨æ¶¨å¹…å‰äº”çš„è¡Œä¸šæ¿å—é‡Œçš„ä¸ªè‚¡
    watchlist2 (é£å£æ¶¨åœæ± ): æ¶¨åœ/ç‚¸æ¿ï¼Œä¸”åœ¨æ¶¨å¹…å‰äº”çš„è¡Œä¸šæ¿å—é‡Œçš„ä¸ªè‚¡
    """
    file_path1 = f"{save_dir}/watchlist1_{date}.csv"
    file_path2 = f"{save_dir}/watchlist2_{date}.csv"

    watchlist1_df = load_local_csv(file_path1)
    watchlist2_df = load_local_csv(file_path2)

    if watchlist1_df is not None and watchlist2_df is not None:
        print("-" * 30)
        print("Watchlist 1 (å¤§é¢å¼‚åŠ¨æ± ):")
        print(watchlist1_df)
        print("Watchlist 2 (é£å£æ¶¨åœæ± ):")
        print(watchlist2_df)
        print("-" * 30)
        return watchlist1_df, watchlist2_df
    
    # --- 1. å»ºç«‹å‰äº”æ¿å—çš„æˆå‘˜åç§°åº“ ---
    # åˆå¹¶å‰äº”ä¸ªæ¿å—çš„æ‰€æœ‰æˆåˆ†è‚¡ï¼Œä»…æå–åç§°ç”¨äºåŒ¹é…
    top_5_member_names = set()
    for df in concept_cons[:5]:
        if not df.empty:
            name_col = 'åç§°' if 'åç§°' in df.columns else 'è‚¡ç¥¨åç§°'
            top_5_member_names.update(df[name_col].tolist())

    # --- 2. å‡†å¤‡å…¶ä»–å¼‚åŠ¨æ± åç§° ---
    zt_names = set(zt_pool_df['åç§°']) if not zt_pool_df.empty else set()
    zb_names = set(zb_pool_df['åç§°']) if not zb_pool_df.empty else set()
    dt_names = set(dt_pool_df['åç§°']) if not dt_pool_df.empty else set()
    
    lhb_col = 'åç§°' if 'åç§°' in lhb_df.columns else 'è‚¡ç¥¨åç§°'
    lhb_names = set(lhb_df[lhb_col]) if not lhb_df.empty else set()

    # --- 3. æ„é€  watchlist1 ---
    # æ¡ä»¶ï¼šåœ¨ top_amount_stocks_df ä¸­ï¼Œä¸”æ»¡è¶³ (æ¶¨/è·Œ/ç‚¸/é¾™/å‰äº”æ¿å—æˆå‘˜) ä»»æ„ä¸€ä¸ª
    w1_mask = (
        top_amount_stocks_df['åç§°'].isin(zt_names) |
        top_amount_stocks_df['åç§°'].isin(dt_names) |
        top_amount_stocks_df['åç§°'].isin(zb_names) |
        top_amount_stocks_df['åç§°'].isin(lhb_names) |
        top_amount_stocks_df['åç§°'].isin(top_5_member_names)
    )
    watchlist1_df = top_amount_stocks_df[w1_mask].copy()

    # --- 4. æ„é€  Watchlist 2 ---
    # é€»è¾‘ï¼šå°†æ¶¨åœæ± å’Œç‚¸æ¿æ± åˆå¹¶ï¼Œæå–å®ƒä»¬çš„å±æ€§
    
    # ç»Ÿä¸€å­—æ®µåï¼ˆé˜²æ­¢ zt_pool å’Œ zb_pool å­—æ®µå¾®å·®å¯¼è‡´åˆå¹¶é”™ä½ï¼‰
    # å¢åŠ ä¸€ä¸ªæ ‡ç­¾åˆ—åŒºåˆ†â€œçŠ¶æ€â€
    zt_temp = zt_pool_df.copy()
    if not zt_temp.empty:
        zt_temp['å½“å‰çŠ¶æ€'] = 'æ¶¨åœ'
        zt_temp['æˆäº¤é¢'] = zt_temp['æˆäº¤é¢'] / 1e8 # è½¬æ¢ä¸ºäº¿å…ƒ
        zt_temp['æµé€šå¸‚å€¼'] = zt_temp['æµé€šå¸‚å€¼'] / 1e8
        zt_temp['æ€»å¸‚å€¼'] = zt_temp['æ€»å¸‚å€¼'] / 1e8
    
    zb_temp = zb_pool_df.copy()
    if not zb_temp.empty:
        zb_temp['å½“å‰çŠ¶æ€'] = 'ç‚¸æ¿'
        zb_temp['æˆäº¤é¢'] = zb_temp['æˆäº¤é¢'] / 1e8 # è½¬æ¢ä¸ºäº¿å…ƒ
        zb_temp['æµé€šå¸‚å€¼'] = zb_temp['æµé€šå¸‚å€¼'] / 1e8
        zb_temp['æ€»å¸‚å€¼'] = zb_temp['æ€»å¸‚å€¼'] / 1e8
    
    # åˆå¹¶ä¸¤ä¸ªæ± å­ 
    combined_limit_df = pd.concat([zt_temp, zb_temp], ignore_index=True, sort=False)
    
    if not combined_limit_df.empty:
        # ç­›é€‰ï¼šå±äºå‰äº”æ¿å—æˆå‘˜çš„ä¸ªè‚¡
        watchlist2_df = combined_limit_df[combined_limit_df['åç§°'].isin(top_5_member_names)].copy()
        
        # æ’åºï¼šå…ˆçœ‹çŠ¶æ€ï¼ˆæ¶¨åœåœ¨å‰ï¼‰ï¼Œå†çœ‹è¿æ¿æ•°ï¼ˆè¶Šé«˜è¶Šå‰ï¼‰
        # æ³¨æ„ï¼šç‚¸æ¿æ± å¯èƒ½æ²¡æœ‰â€œè¿æ¿æ•°â€å­—æ®µï¼Œéœ€è¦å¡«å…… 0 é¿å…æ’åºæŠ¥é”™
        if 'è¿æ¿æ•°' in watchlist2_df.columns:
            watchlist2_df['è¿æ¿æ•°'] = watchlist2_df['è¿æ¿æ•°'].fillna(0)
            watchlist2_df.sort_values(by=['å½“å‰çŠ¶æ€', 'è¿æ¿æ•°'], ascending=[False, False], inplace=True)
    else:
        watchlist2_df = pd.DataFrame()

    watchlist1_df.drop(columns=['åºå·'], inplace=True, errors='ignore')
    watchlist1_df.reset_index(drop=True, inplace=True)
    watchlist1_df.insert(0, 'åºå·', range(1, len(watchlist1_df) + 1))

    watchlist2_df.drop(columns=['åºå·'], inplace=True, errors='ignore')
    watchlist2_df.reset_index(drop=True, inplace=True)
    watchlist2_df.insert(0, 'åºå·', range(1, len(watchlist2_df) + 1))
    
    print("-" * 30)
    print("Watchlist 1 (å¤§é¢å¼‚åŠ¨æ± ):")
    print(watchlist1_df)
    print("-" * 30)
    print("Watchlist 2 (é£å£æ¶¨åœæ± ):")
    print(watchlist2_df)
    print("-" * 30)

    # ä¿å­˜ watchlist åˆ°æœ¬åœ°æ–‡ä»¶
    watchlist1_df.to_csv(file_path1, index=False, encoding="utf-8-sig")
    watchlist2_df.to_csv(file_path2, index=False, encoding="utf-8-sig")

    return watchlist1_df, watchlist2_df

def create_hugo_post(
        index_df, up_count, down_count,
        zt_pool_df, dt_pool_df, zb_pool_df,
        top_amount_stocks_df,
        concept_summary_df, concept_cons_topn,
        lhb_df,
        watchlist1_df, watchlist2_df,
        save_dir='content/posts'):
    """ç”Ÿæˆç¬¦åˆç‘å£«æ—¶åŒºä¸”é˜² Hugo å±è”½çš„æ–‡ç« """
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(save_dir, exist_ok=True)
    
    # 1. å¤„ç†ç‘å£«æ—¶åŒº
    swiss_tz = pytz.timezone('Europe/Zurich')
    # 2. å°†æ—¶é—´å¾€å‰æ‹¨ 10 åˆ†é’Ÿï¼Œç¡®ä¿ 100% åˆ¤å®šä¸ºâ€œå·²å‘å¸ƒâ€
    safe_now = datetime.now(swiss_tz) - timedelta(minutes=10)
    
    # ç”Ÿæˆæ–‡ä»¶åå’Œ ISO æ—¶é—´æˆ³
    date_filename = safe_now.strftime("%Y-%m-%d")
    # æ ¼å¼ç¤ºä¾‹: 2026-02-12T20:15:00+01:00
    formatted_date = safe_now.strftime("%Y-%m-%dT%H:%M:%S%z")
    
    filename = f"{save_dir}/stock-analysis-{date_filename}.md"
    display_title = f"Aè‚¡å…¨å¸‚åœºå¤ç›˜ï¼š{date_filename} æ·±åº¦è§£æåŠAIæ´å¯Ÿ"

    content = f"""---
title: "{display_title}"
date: {formatted_date}
tags: ["æ¯æ—¥å¤ç›˜", "é‡ç‚¹ä¸ªè‚¡", "è¡Œä¸šæ¿å—", "å¸‚åœºåˆ†æ"]
categories: ["æ¯æ—¥æ›´æ–°"]
showToc: true
draft: false
---


### ğŸ“Š å¸‚åœºæ ¸å¿ƒå¿«ç…§
- **ä¸Šè¯æŒ‡æ•°**: {index_df.iloc[0]['æœ€æ–°ä»·']} ({index_df.iloc[0]['æ¶¨è·Œå¹…']}%)
- **å…¨å¸‚åœºæˆäº¤æ€»é¢**: {index_df.iloc[0]['æˆäº¤é¢(äº¿å…ƒ)']:.2f} äº¿
- **æ¶¨è·Œæ¯”**: {up_count} / {down_count}
- **æ¶¨åœ/è·Œåœ/ç‚¸æ¿æ•°**: {len(zt_pool_df)} / {len(dt_pool_df)} / {len(zb_pool_df)}

---

### ğŸ” æˆäº¤é¢å‰äºŒåä¸ªè‚¡

{top_amount_stocks_df.to_markdown(index=False)}

---

### ğŸ† è¡Œä¸šæ¿å—åˆ†æ
- **å‰äº”æ¦‚å¿µæ¿å—**ï¼ˆæŒ‰æ¶¨å¹…æ’åºï¼‰

{concept_summary_df.to_markdown(index=False)}

- **å„æ¿å—æ¿å—æ¶¨å¹…é å‰ä¸ªè‚¡**ï¼ˆæŒ‰æ¶¨å¹…æ’åºï¼‰

-- æ¿å—1. {concept_cons_topn[0]['æ‰€å±æ¿å—'].iloc[0]} --

{concept_cons_topn[0].to_markdown(index=False)}

-- æ¿å—2. {concept_cons_topn[1]['æ‰€å±æ¿å—'].iloc[0]} --

{concept_cons_topn[1].to_markdown(index=False)}

-- æ¿å—3. {concept_cons_topn[2]['æ‰€å±æ¿å—'].iloc[0]} --

{concept_cons_topn[2].to_markdown(index=False)}

-- æ¿å—4. {concept_cons_topn[3]['æ‰€å±æ¿å—'].iloc[0]} --

{concept_cons_topn[3].to_markdown(index=False)}

-- æ¿å—5. {concept_cons_topn[4]['æ‰€å±æ¿å—'].iloc[0]} --

{concept_cons_topn[4].to_markdown(index=False)}

---

### ğŸ’¥ æ¶¨åœ/ç‚¸æ¿ä¸ªè‚¡

-- æ¶¨åœæ±  --

{zt_pool_df.to_markdown(index=False)}

-- ç‚¸æ¿æ±  --

{zb_pool_df.to_markdown(index=False)}

---

### ğŸš€ é¾™è™æ¦œ

{lhb_df.to_markdown(index=False)}

---

### â­ é‡ç‚¹ä¸ªè‚¡ Watchlist
- **å¤§é¢å¼‚åŠ¨æ± **ï¼ˆæˆäº¤é¢å‰äºŒåï¼Œä¸”åœ¨æ¶¨/è·Œ/ç‚¸/é¾™è™æ¦œ/å‰äº”æ¿å—æˆå‘˜ä¸­ï¼‰

{watchlist1_df.to_markdown(index=False)}

- **é£å£æ¶¨åœæ± **ï¼ˆæ¶¨åœ/ç‚¸æ¿ï¼Œä¸”åœ¨å‰äº”æ¿å—æˆå‘˜ä¸­ï¼‰

{watchlist2_df.to_markdown(index=False)}

---
*æ³¨ï¼š
1. æ•°æ®æ¥æºï¼šAKShareã€‚
2. æœ¬æ–‡ç”±AIè¾…åŠ©ç”Ÿæˆï¼Œæ—¨åœ¨æä¾›å¸‚åœºæ´å¯Ÿå’Œæ•°æ®åˆ†æï¼ŒéæŠ•èµ„å»ºè®®ã€‚
3. å£°æ˜ï¼šæŠ•èµ„æœ‰é£é™©ï¼Œå…¥å¸‚éœ€è°¨æ…ã€‚æœ¬æ–‡å†…å®¹ä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆä»»ä½•æŠ•èµ„å»ºè®®æˆ–æ¨èã€‚è¯·æ ¹æ®è‡ªèº«æƒ…å†µåšå‡ºç‹¬ç«‹åˆ¤æ–­ã€‚*
"""
    
    with open(filename, "w", encoding="utf-8") as f:
        f.write(content)
    print(f"æˆåŠŸç”ŸæˆæŠ¥å‘Š: {filename}")
    print(f"æ–‡ç« å‘å¸ƒæ—¶é—´è®¾ä¸º: {formatted_date}")

def fetch_and_save():
    """ä¸»å‡½æ•°ï¼šè·å–æ•°æ®å¹¶ä¿å­˜"""
    latest_date = get_latest_date()
    # latest_date = datetime.now().strftime("%Y%m%d")
    if latest_date is None:
        print("âŒ æ— æ³•ç¡®å®šæœ€æ–°æ•°æ®æ—¥æœŸï¼Œè„šæœ¬ç»ˆæ­¢ã€‚")
        exit(1)
    os.makedirs("data", exist_ok=True)
    save_dir = f"data/{latest_date}"
    os.makedirs(save_dir, exist_ok=True)

    # è·å–å¤§ç›˜æ•°æ®å¹¶ä¿å­˜
    index_df = stock_summary(date=latest_date, save_dir=save_dir)

    # è·å–æ¶¨åœæ•°æ®å¹¶ä¿å­˜
    zt_pool_df, dt_pool_df, zb_pool_df = stock_zt_dt_pool(date=latest_date, save_dir=save_dir)
    # TODO: è¿æ¿æ•°æ®åˆ†æ

    # è·å–æ‰€æœ‰è‚¡ç¥¨æ•°æ®å¹¶ä¿å­˜
    all_stocks_df, up_count, down_count, flat_count = fetch_all_stock_data(date=latest_date, save_dir=save_dir, max_retries=3)

    # æˆäº¤é‡å‰äºŒåçš„ä¸ªè‚¡åç§°ã€æˆäº¤é¢ã€æ¶¨å¹…ã€ä»¥åŠæ‰€å±æ¿å—æˆ–è€…æ¦‚å¿µ
    top_amount_stocks_df = get_top_amount_stocks(all_stocks_df, top_n=20, date=latest_date, save_dir=save_dir)

    # æ¶¨å¹…å‰äº”æ¿å—ä¸­æ¶¨åœä¸ªè‚¡ã€è¿æ¿é«˜åº¦ï¼ˆå‡ å¤©å‡ æ¿ã€é¦–æ¿åæ¶¨å¹…ï¼‰
    # # åŒèŠ±é¡º-åŒèŠ±é¡ºè¡Œä¸šä¸€è§ˆè¡¨
    # industry_summary_df = get_industry_summary(date=latest_date, save_dir=save_dir)
    
    # ä¸œæ–¹è´¢å¯Œ-æ¦‚å¿µæ¿å— å®æ—¶è¡Œæƒ…æ•°æ®
    concept_summary_df = get_concept_summary(date=latest_date, save_dir=save_dir)

    # æ¦‚å¿µæ¿å—æˆåˆ†è‚¡æ•°æ®
    concept_cons, concept_cons_topn = get_concept_cons(concept_summary_df, date=latest_date, save_dir=save_dir)

    # é¾™è™æ¦œ
    lhb_df = get_lhb_data(date=latest_date, save_dir=save_dir)

    # é‡ç‚¹ä¸ªè‚¡ä¿¡æ¯
    watchlist1_df, watchlist2_df = get_watchlist(
                                                    top_amount_stocks_df,
                                                    zt_pool_df,
                                                    zb_pool_df,
                                                    dt_pool_df,
                                                    lhb_df,
                                                    concept_cons,
                                                    date=latest_date,
                                                    save_dir=save_dir
                                                )

    # TODO: çƒ­åº¦æ¦œ

    # TODO: è·å–èµ„è®¯

    # TODO: åˆ†ææŠ¥å‘Š

    # ç”ŸæˆHugoè§„æ ¼çš„ Markdown æŠ¥å‘Š
    create_hugo_post(
        index_df=index_df,
        zt_pool_df=zt_pool_df,
        dt_pool_df=dt_pool_df,
        zb_pool_df=zb_pool_df,
        up_count=up_count,
        down_count=down_count,
        top_amount_stocks_df=top_amount_stocks_df,
        concept_summary_df=concept_summary_df,
        concept_cons_topn=concept_cons_topn,
        lhb_df=lhb_df,
        watchlist1_df=watchlist1_df,
        watchlist2_df=watchlist2_df,
        save_dir='content/posts'
    )

    return True
    

if __name__ == "__main__":
    fetch_and_save()
                                                                                                                    